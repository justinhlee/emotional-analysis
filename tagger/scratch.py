# ----- TESTING SET 
        #top_words = extract_top_words(blog_directory)
        # blog_directory = 'testing-output'
        # dict1 = 'anew.txt'
        # d = dict1
        # t = Tagger(d, 'anew')
        # t.tag_directory(blog_directory)
        # towrite = open('testing', 'w')
        # t.score_valence(True)
        # ids = get_list_of_ids('id_scored_valence.txt')
        # get_blogs_from_ids('top_scored_valence.txt', ids, 'testing-entries')
        # n = len(ids)
        # completed = 0
        # for blog_id in ids:
        #     path = 'testing-output/' + blog_id + '.xml'
        #     towrite.write(format_to_libsvm(map_unigrams(path, top_words), True) + '\n')
        #     completed += 1
        #     if (completed % 30) == 0:
        #         print '%.2f' % (completed*100/float(n)) + '% of testing data written.'


        # get_blogs_from_ids('top_scored_valence.txt', l, 'entries')
        # l = map_unigrams('entries-output/2143.txt.xml', top_words)
        # format_to_libsvm(l, False)
        

       
        # get_blogs_from_ids('top_scored_valence.txt', l, 'entries')


        # t.score_joy()
        # l = get_list_of_ids('id_scored_joy.txt')
        # get_blogs_from_ids('top_scored_joy.txt', l, 'entries')


        # t.get_tagged_from_high_coverage(50)
        # t.get_high_coverage_blogs(50)
        # t.get_high_occurrence_blogs(50)